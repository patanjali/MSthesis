Computers have evolved from being glorified calculators that occupied the space of a large building to small pervasive devices. This rapid growth, however, has increased the expectations that the end user places on today's digital devices which, in turn, has increased the number of constraints on the device. This thesis considers two such objectives viz, power and security and proposes design level techniques to address the same.

Today's devices are expected to be extremely performance efficient with both servers and mobile phones expected to run the same workload, e.g., statistical inference algorithms, smaller in size and have a lower energy footprint to enable ubiquity in deployment. This creates challenges for digital designers as these constraints are orthogonal causing designers to sacrifice one or more of these objectives. The exponential growth in the number of EDGE devices has also impacted the device manufacturing time which creates a unique challenge for the digital designer as the design is now expected to meet three orthogonal constraints in a short amount of time. Our proposed MLTimer solution presented in this thesis addresses this problem that uses a novel data-driven algorithm which lets the designer re-use solutions from previously optimized circuits to meet the power constraints for  a given design. We show that the proposed solution outperforms the state-of-the-art solutions by evaluating it on the ISPD2012, ISPD2013 benchmark circuits. We compare the results with a commercial EDA flow by evaluating the proposed solution to optimize a state-of-the-art embedded processor running Linux.

The recent Meltdown and Cambridge Analytica data leaks have sensitized the common man to the importance of a secure software and hardware computing platform. While software vulnerabilities can be fixed by implementing a patch with minimal overheads, hardware vulnerabilities, otherwise known as side-channels, are harder to detect and correct. In this thesis, we consider the problem of power side-channels on embedded devices and propose a gate-sizing based solution to reduce the risk of a digital device through the power side-channel. Our proposed solution, Karna, is the first design level solution. We quantify the effectiveness of Karna along with the area, delay and performance overheads by evaluating the proposed scheme on three different block ciphers.


%This thesis studies the following topics in the area of Reinforcement Learning: classic Multi-armed bandits in stationary distribution with the goal of cumulative regret minimization using variance estimates and Thresholding bandits in pure exploration fixed-budget setting with the goal of instantaneous regret minimization also using variance estimates. The common underlying theme is the study of bandit theory and its application in various types of environments. In the first part of the thesis, we study the classic multi-armed bandit problem with a stationary distribution, one of the first settings studied by the bandit community and which successively gave rise to several new directions in bandit theory. We propose a novel algorithm in this setting and compare both theoretically and empirically its performance against the available algorithms. Our proposed algorithm termed as Efficient-UCB-Variance (EUCBV) is the first arm-elimination algorithm which uses variance estimation to eliminate arms as well as achieve an order optimal regret bound. Empirically, we show that EUCBV outperforms most of the state-of-the-art algorithms in the considered environments. In the next part, we study a specific type of stochastic multi-armed bandit setup called the thresholding bandit problem and discuss its usage, available state-of-the-art algorithms on this setting and our solution to this problem. We propose the Augmented-UCB (AugUCB) algorithm which again uses variance and mean estimation along with arm elimination technique to conduct exploration. We give theoretical guarantees on the expected loss of our algorithm and also analyze its performance against state-of-the-art algorithms in numerical simulations in multiple synthetic environments. 