\documentclass[PhD]{iitmdiss}
%\documentclass[MS,twoside]{iitmdiss}
%\documentclass[MTech]{iitmdiss}
%\documentclass[BTech]{iitmdiss}
\usepackage{times}
 \usepackage{t1enc}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{hyperref} % hyperlinks for references.
\usepackage{amsmath} % easier math formulae, align, subequations \ldots
\usepackage{caption}
\usepackage[ruled,linesnumbered]{algorithm2e} % For algorithms
%\usepackage{subfig}
 \usepackage{subcaption}
 \usepackage{xfrac}
 \usepackage{nicefrac}
% \usepackage{footnote}
% \makesavenoteenv{tabular}
 \usepackage[font=small,labelfont=bf]{caption}
 \usepackage{booktabs}
 \usepackage{multirow}
 \usepackage[font={footnotesize}]{caption}
 \usepackage{amsthm}
\newtheorem{thm}{Theorem}[] % the main one
\newtheorem{lemma}[thm]{Lemma}
\theoremstyle{plain} % just in case the style had changed
 \newcommand{\thistheoremname}{}
 \newtheorem{genericthm}[thm]{\thistheoremname}
 \newenvironment{namedthm}[1]
   {\renewcommand{\thistheoremname}{#1}%
   \begin{genericthm}}
   {\end{genericthm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{ijcai17}
\SetKw{Continue}{continue}


\usepackage{macros}

\usepackage{latexsym} 



\newcommand{\clearemptydoublepage}{\newpage{\cleardoublepage}}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title page

\title{Gate sizing for energy efficient and secure digital designs.}

\author{Patanjali SLPSK}

\date{January 2018}
\department{COMPUTER SCIENCE AND ENGINEERING}

%\nocite{*}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Certificate

%\pagebreak
%\newpage
% \ 
%\thispagestyle{empty}
%\clearpage

\clearemptydoublepage
\certificate

\vspace*{0.5in}

\noindent This is to certify that the thesis titled {\bf Gate sizing for energy efficient and secure digital designs}, submitted by {\bf Patanjali SLPSK}, 
  to the Indian Institute of Technology, Madras, for
the award of the degree of {\bf Doctor of Philosophy}, is a bona fide
record of the research work done by him under our supervision.  The
contents of this thesis, in full or in parts, have not been submitted
to any other Institute or University for the award of any degree or
diploma.

\vspace*{1.5in}

\begin{singlespacing}
\hspace*{-0.25in}
\parbox{2.5in}{
\noindent {\bf Dr. Kamakoti Veezhinathan} \\
\noindent Research Guide \\ 
\noindent Professor \\
\noindent Dept. of Computer Science\\
\noindent IIT-Madras, 600 036 \\
} 

\end{singlespacing}
\vspace*{0.25in}
\noindent Place: Chennai\\
Date: January, 2018


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Acknowledgements
\clearemptydoublepage
\acknowledgements
%To be written.
\input{ack}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
\clearemptydoublepage
\abstract

%\noindent KEYWORDS: \hspace*{0.5em} \parbox[t]{4.4in}{Reinforcement Learning, Bandits, UCB, EUCBV, Thresholding Bandits,  AugUCB, changepoint detection, SECPD.}

%\noindent KEYWORDS: \hspace*{0.5em} \parbox[t]{4.4in}{Reinforcement Learning, Stochastic Bandits, UCB, UCBV, EUCBV, Thresholding Bandits, APT, AugUCB}

\vspace*{24pt}
\noindent \input{abstract}

%The thesis studies the following topics in the area of Reinforcement Learning: Multi-armed Bandits, Multi-armed bandits in stationary distribution with the goal of cumulative regret minimization and Thresholding bandits in pure exploration setting. The common underlying theme is the study of bandit theory and its application in various types of environments. We start with a general introduction to Multi-armed bandits, its connection to the wider reinforcement learning theory and then we discuss the various types of bandits available in the literature. Then we delve deep into the classic multi-armed bandit problem in stationary distribution, one of the first setting studied by the bandit community and which successively gave rise to several new directions in bandit theory. We propose a novel algorithm in this setting and compare both theoretically and empirically its performance against the available algorithms in this setting. Subsequently, we study a very specific type of bandit setup called the thresholding bandit problem and discuss extensively on its usage, available state-of-the-art algorithms on this setting and our solution to this problem. We give theoretical guarantees on the expected loss of our algorithm and also analyze its performance against state-of-the-art algorithms in numerical simulations in multiple synthetic environments. 

%, and analysis of bandit theory in piece-wise stationary distributions

%Finally, we study the notion of piece-wise stationary distribution and how available bandit algorithms can be modified to perform well in this setting. We propose a set of algorithms for this setting with the goal of minimizing cumulative regret which uses various techniques ranging from changepoint detection mechanism to aggregation of experts.

%\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Table of contents etc.
\clearemptydoublepage
\begin{singlespace}
\tableofcontents
%\thispagestyle{empty}

\clearemptydoublepage
\listoftables
\addcontentsline{toc}{chapter}{LIST OF TABLES}


\clearemptydoublepage
\listoffigures
\addcontentsline{toc}{chapter}{LIST OF FIGURES}
\end{singlespace}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abbreviations
\clearemptydoublepage
\abbreviations

\noindent 
\begin{tabbing}
xxxxxxxxxxx \= xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \kill
%\textbf{RL}   \> Reinforcement Learning \\
%\textbf{MAB} \> Multi-armed Bandit \\
%\textbf{SMAB} \> Stochastic Multi-armed Bandit \\
%\textbf{UCB} \> Upper Confidence Bound \\
%\textbf{MOSS} \> Minimax Optimal Strategy in the Stochastic case \\
%\textbf{UCBV} \> Upper Confidence Bound Variance \\
%\textbf{OCUCB} \> Optimally Confident Upper Confidence Bound \\
%\textbf{KLUCB} \> Kullback–Leibler Upper Confidence Bound \\
%\textbf{TS} \> Thompson Sampling \\
%\textbf{EUCBV} \> Efficient Upper Confidence Bound Variance \\
%\textbf{TBP} \> Thresholding Bandit Problem \\
%\textbf{UCBE} \> Upper Confidence Bound Exploration\\
%\textbf{UCBEV} \> Upper Confidence Bound Exploration Variance\\
%\textbf{UA} \> Uniform Allocation \\
%\textbf{SR} \> Successive Reject \\
%\textbf{CSAR} \> Combinatorial Successive Accept Reject \\
%\textbf{APT} \> Anytime Parameter-free Thresholding \\
%\textbf{AugUCB} \> Augmented Upper Confidence Bound \\
\textbf{APT} \> Anytime Parameter-free Thresholding \\
\textbf{AugUCB} \> Augmented Upper Confidence Bound \\
%BIB
\textbf{BU} \> Bayes-UCB \\
\textbf{CCB} \> Combined Confidence Bound \\
%CPD
%CPDI
\textbf{CSAR} \> Combinatorial Successive Accept Reject \\
%CUSUM
%DBLP
\textbf{DMED} \> Deterministic Minimum Empirical Divergence \\
\textbf{DTS} \> Discounted Thompson Sampling \\
\textbf{DUCB} \> Discounted UCB \\
%DVI
\textbf{EUCBV} \> Efficient Upper Confidence Bound Variance \\
%EVE
\textbf{EXP3} \> Exponential Exploration Exploitation \\
\textbf{EXP3IX} \> EXP3 Implicit Exploration \\
\textbf{GCTS} \> Global Change-ponit Thompson Sampling \\
%GK
%IITM
\textbf{KL} \> Kullback–Leibler \\
\textbf{KLUCB} \> Kullback–Leibler Upper Confidence Bound \\
%KT
%LHS
\textbf{LUCB} \> Lower Upper Confidence Bound \\
\textbf{MAB} \> Multi-armed Bandit \\
\textbf{MDP} \> Markov Decision Process \\
\textbf{MOSS} \> Minimax Optimal Strategy in the Stochastic case \\
%MS
\textbf{OCUCB} \> Optimally Confident Upper Confidence Bound \\
%\textbf{OTS} \> Oracle Thompson Sampling \\
%PDF
\textbf{RL}   \> Reinforcement Learning \\
\textbf{RExp3}   \> Restarting EXP3 \\
\textbf{SAR} \> Successive Accept Reject \\
%SECPD
\textbf{SMAB} \> Stochastic Multi-armed Bandit \\
\textbf{SR} \> Successive Reject \\
\textbf{SW-UCB} \> Switching Window UCB \\ 
\textbf{TBP} \> Thresholding Bandit Problem \\
\textbf{TS} \> Thompson Sampling \\
\textbf{UA} \> Uniform Allocation \\
\textbf{UCB} \> Upper Confidence Bound \\
\textbf{UCBE} \> Upper Confidence Bound Exploration\\
\textbf{UCBEV} \> Upper Confidence Bound Exploration Variance\\
\textbf{UCBV} \> Upper Confidence Bound Variance \\
%URL



\end{tabbing}

%\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Notation

\clearemptydoublepage
\chapter*{\centerline{NOTATION}}
\addcontentsline{toc}{chapter}{NOTATION}

\begin{singlespace}
\begin{tabbing}
xxxxxxxxxxx \= xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \kill
\textbf{$T$} \> Time horizon\\
\textbf{$\A$} \> Set of arms\\
\textbf{$K$} \> Total number of arms\\
\textbf{$\pi$}   \> Policy of an agent \\
\textbf{$D_i$}  \> Reward distribution of $i$-th arm \\
\textbf{$r_i$}  \> Expected mean of $D_i$ for the $i$-th arm \\
\textbf{$\hat{r}_i$}  \> Sample mean of the $i$-th arm \\
\textbf{$X_{i,t}$} \> Reward obtained for the $i$-th arm at the $t$-th timestep\\
\textbf{$z_i$}  \> Number of times arm $i$ is pulled\\
\textbf{$\sigma_i$} \> Standard Deviation of the $i$-th arm\\
\textbf{$v_i$} \> Variance of the $i$-th arm\\
\textbf{$\Delta_i$} \> Gap of the $i$-th arm\\
\textbf{$\Delta$} \> Minimal gap amongst all arms\\
\textbf{$\tau$} \> Threshold\\
\textbf{$H_1$} \> Hardness with Mean-$1$\\
\textbf{$H_2$} \> Hardness with Mean-$2$\\
\textbf{$H_{\sigma,1}$} \> Hardness with Mean and Standard Deviation-$1$\\
\textbf{$H_{\sigma,2}$} \> Hardness with Mean and Standard Deviation-$2$\\
\textbf{$\rho$} \> Parameter for tuning length of of confidence interval\\
\textbf{$\psi$} \> Exploration parameter\\
\textbf{$m$} \> Round number\\
\textbf{$R_T$} \> Cumulative regret till horizon $T$\\
\textbf{$SR_t$} \> Simple regret at $t$-th timestep\\
\end{tabbing}
\end{singlespace}

%\pagebreak
%\clearpage

% The main text will follow from this point so set the page numbering
% to arabic from here on.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction.
\clearemptydoublepage
\pagenumbering{arabic}
\chapter{Introduction}
\label{chap:intro}

\section{Reinforcement Learning}
\label{intro}
\input{Chapter1/intro}

\section{Connection between Reinforcement Learning and Bandits}
\label{conn:Bandits}
%\input{Chapter1/connBandits}

\section{Why study Bandits?}
\label{study}
%\input{Chapter1/studyBandit}

\section{Motivation}
\label{motivation}
%\input{Chapter1/motivation}


\section{Types of Information Feedback}
\label{feed}
\input{Chapter1/feedback}


\section{Different types of Bandits}
\label{types}
\input{Chapter1/types}


\section{Objectives of Thesis}
\label{objThesis}
\input{Chapter1/objective}

\section{Contributions of Thesis}
\label{contriThesis}
\input{Chapter1/contribution}

\section{Outline of the Thesis}
\label{outline}
\input{Chapter1/outline}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearemptydoublepage
% \chapter{Stochastic Multi-armed Bandits}
% \label{chap:SMAB}

% \section{Introduction to SMAB}
% \label{sec:intro}
% \input{Chapter2/intro}

% \section{Notations and assumptions}
% \label{sec:notations}
% \input{Chapter2/notation}

% \section{Problem Definition}
% \label{sec:probDef}
% \input{Chapter2/probDef}

% \section{Motivation}
% \label{sec:motivation}
% \input{Chapter2/motivation}

% \section{Related Work in SMAB}
% \label{sec:related}
% \input{Chapter2/related}

% \newpage
% \section{Summary}
% \label{chap2:conc}
% \input{Chapter2/conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearemptydoublepage
\chapter{Efficient UCB Variance: An Almost Optimal Algorithm in SMAB Setting}
\label{chap:EUCBV}
\input{Chapter3/introduction.tex}
\input{Chapter3/background.tex}
\input{Chapter3/motivation.tex}
\input{Chapter3/problem.tex}
\input{Chapter3/proposed.tex}
\input{Chapter3/related.tex}
\input{Chapter3/results.tex}
% \section{Introduction}
% \label{Chapter3:intro}
% \input{Chapter3/introduction}


% \section{Our Contributions}
% \label{sec:contri}
% %\input{Chapter3/contribution}

% \section{Algorithm: Efficient UCB Variance}
% \label{sec:eucbv}
% \input{Chapter3/ealgo}

% \section{Main Results} 
% \label{sec:results}
% \input{Chapter3/results}

% \section{Proofs}
% \label{sec:proofTheorem}
% \input{Chapter3/proofTheorem}

% \section{Experiments}
% \label{sec:expt}
% \input{Chapter3/expts}

% \section{Summary}
% \label{sec:conc}
% \input{Chapter3/Conclusion}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearemptydoublepage
\chapter{Thresholding Bandits}
\label{chap:tbandit1}

%\section{Introduction to Thresholding Bandits}
%\label{tbandit:intro1}
\input{Chapter4/introduction.tex}

%\section{Notations and Assumptions}
%\label{tbandit:notations}
\input{Chapter4/background.tex}

%\section{Problem Definition}
%\label{tbandit:probDef}
\input{Chapter4/motivation.tex}

%section{Motivation}
%\label{tbandit:motivation}
\input{Chapter4/experiment.tex}

%\section{Related Work in Pure Exploration Problem}
%\label{tbandit:prevRes}
\input{Chapter4/proposed.tex}

%\section{TBP Connection to Pure Exploration Problem}
%\label{tbandit:connection}
\input{Chapter4/related.tex}


% \section{Related Work in Thresholding Bandits}
% \label{tbandit:prevResAPT}
% \input{Chapter4/prevResAPT}


\section{Summary}
%\label{tbandit:conc}
%\input{Chapter4/conc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearemptydoublepage
% \chapter{Augmented UCB for Thresholding Bandit Problem}
% \label{chap:tbandit2}

% \section{Introduction}
% \label{tbandit:intro2}
% \input{Chapter5/intro}


% \section{Our Contributions}
% \label{tbandit:contribution}
% \input{Chapter5/contribution}


% \section{Augmented-UCB Algorithm}
% \label{tbandit:algorithm}
% \input{Chapter5/algo}


% \section{Theoretical Results}
% \label{tbandit:results}
% \input{Chapter5/results}


% \section{Numerical Experiments}
% \label{tbandit:expt}
% \input{Chapter5/expt}


% \section{Summary}
% \label{tbandit:conclusion}
% \input{Chapter5/conclusion}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\chapter{Improved Changepoint Detection for Piecewise Stationary Distributions}
%\label{chap:psbandit}
%
%\section{Introduction}
%\label{psbandit:intro}
%\input{Chapter6/intro}
%
%\section{Notations, Assumptions and Definitions}
%\label{psbandit:notations}
%\input{Chapter6/notations}
%
%\section{Problem Definitions}
%\label{psbandit:probDef}
%\input{Chapter6/probDef}
%
%\section{Related Works}
%\label{psbandit:related}
%\input{Chapter6/related}
%
%\section{Our Contribution}
%\label{psbandit:contribution}
%\input{Chapter6/contribution}
%
%\section{Changepoint Detection Algorithms}
%\label{psbandit:algorithm}
%\input{Chapter6/algo1}
%
%
%\section{Theoretical Results}
%\label{psbandit:results}
%\input{Chapter6/mainresult}
%
%
%\section{Numerical Experiments}
%\label{psbandit:expt}
%To be written
%%\input{Chapter6/expt}
%
%
%\section{Summary}
%\label{psbandit:conclusion}
%\input{Chapter6/conclusion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearemptydoublepage
\chapter{Conclusions and Future Directions}
\label{ThesisConc}

\section{Conclusions}
\input{Chapter7/ThesisConc}

\section{Future Directions}
\input{Chapter7/ThesisDir}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendices.

\appendix

%\chapter{APPENDIX}
\clearemptydoublepage
\chapter{Appendix on Concentration Inequalities}
\label{sec:app:Conc}
\input{Appendix/AppendixConc}

%\newpage

%\chapter{Appendix for EUCBV}
%\label{sec:app:EUCBV}
%\input{Appendix/AppendixEUCBV}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography.
\clearemptydoublepage
\begin{singlespace}
\bibliographystyle{iitm}
\bibliography{refs}
\end{singlespace}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% List of papers

\clearemptydoublepage
\listofpapers

%\begin{enumerate}  
%\item Authors....  \newblock
% Title...
%  \newblock {\em Journal}, Volume,
%  Page, (year).
%\end{enumerate}  

%\begin{enumerate}
%\item Subhojyoti Mukherjee, K.P.~Naveen, Nandan Sudarsanam, and Balaraman Ravindran, ``\textit{Thresholding Bandit with Augmented UCB}'', \newblock{\em Proceedings of the Twenty-Sixth International Joint Conference on
%               Artificial Intelligence, {IJCAI} 2017, Melbourne, Australia, August
%               19-25, 2017,2515-2521}, main conference track.
%\item Subhojyoti Mukherjee, K.P.~Naveen, Nandan Sudarsanam, and Balaraman Ravindran, ``\textit{Efficient UCBV: An Almost Optimal Algorithm using Variance Estimates}'', \newblock{\em To appear in Proceedings of the Thirty-Second Association for the Advancement of Artificial Intelligence, {AAAI} 2018}, main conference track.
%\end{enumerate}

\begin{enumerate}
\item Subhojyoti Mukherjee, K.P.~Naveen, Nandan Sudarsanam, and Balaraman Ravindran, ``\textit{Thresholding Bandit with Augmented UCB}'', \newblock{\em Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence, {IJCAI} 2017, Melbourne, Australia, August
               19-25, 2017,2515-2521}.
\item Subhojyoti Mukherjee, K.P.~Naveen, Nandan Sudarsanam, and Balaraman Ravindran, ``\textit{Efficient UCBV: An Almost Optimal Algorithm using Variance Estimates}'', \newblock{\em To appear in Proceedings of the Thirty-Second Association for the Advancement of Artificial Intelligence, {AAAI} 2018, New Orleans, Louisiana, USA, February 2-7}.
\end{enumerate}

% Details of commettee members for MS/PhD candidates
\input{committee}

% Curriculum Vitae
\input{cv}



\end{document}
